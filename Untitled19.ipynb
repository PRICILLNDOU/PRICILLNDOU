{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64da787f",
   "metadata": {},
   "source": [
    "# 1 Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f356b4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: advertools in c:\\users\\vhafu\\.conda\\lib\\site-packages (0.13.5)\n",
      "Requirement already satisfied: pandas>=1.1.0 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from advertools) (1.5.3)\n",
      "Requirement already satisfied: pyasn1>=0.4 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from advertools) (0.4.8)\n",
      "Requirement already satisfied: scrapy>=2.5.0 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from advertools) (2.8.0)\n",
      "Requirement already satisfied: twython>=3.8.0 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from advertools) (3.9.1)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from advertools) (11.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from pandas>=1.1.0->advertools) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from pandas>=1.1.0->advertools) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from pandas>=1.1.0->advertools) (1.24.3)\n",
      "Requirement already satisfied: Twisted>=18.9.0 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from scrapy>=2.5.0->advertools) (22.10.0)\n",
      "Requirement already satisfied: cryptography>=3.4.6 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from scrapy>=2.5.0->advertools) (41.0.2)\n",
      "Requirement already satisfied: cssselect>=0.9.1 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from scrapy>=2.5.0->advertools) (1.1.0)\n",
      "Requirement already satisfied: itemloaders>=1.0.1 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from scrapy>=2.5.0->advertools) (1.0.4)\n",
      "Requirement already satisfied: parsel>=1.5.0 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from scrapy>=2.5.0->advertools) (1.6.0)\n",
      "Requirement already satisfied: pyOpenSSL>=21.0.0 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from scrapy>=2.5.0->advertools) (23.2.0)\n",
      "Requirement already satisfied: queuelib>=1.4.2 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from scrapy>=2.5.0->advertools) (1.5.0)\n",
      "Requirement already satisfied: service-identity>=18.1.0 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from scrapy>=2.5.0->advertools) (18.1.0)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from scrapy>=2.5.0->advertools) (1.21.0)\n",
      "Requirement already satisfied: zope.interface>=5.1.0 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from scrapy>=2.5.0->advertools) (5.4.0)\n",
      "Requirement already satisfied: protego>=0.1.15 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from scrapy>=2.5.0->advertools) (0.1.16)\n",
      "Requirement already satisfied: itemadapter>=0.1.0 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from scrapy>=2.5.0->advertools) (0.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vhafu\\.conda\\lib\\site-packages (from scrapy>=2.5.0->advertools) (68.0.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\vhafu\\.conda\\lib\\site-packages (from scrapy>=2.5.0->advertools) (23.0)\n",
      "Requirement already satisfied: tldextract in c:\\users\\vhafu\\.conda\\lib\\site-packages (from scrapy>=2.5.0->advertools) (3.2.0)\n",
      "Requirement already satisfied: lxml>=4.3.0 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from scrapy>=2.5.0->advertools) (4.9.2)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from scrapy>=2.5.0->advertools) (2.0.5)\n",
      "Requirement already satisfied: requests>=2.1.0 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from twython>=3.8.0->advertools) (2.31.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.4.0 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from twython>=3.8.0->advertools) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from cryptography>=3.4.6->scrapy>=2.5.0->advertools) (1.15.1)\n",
      "Requirement already satisfied: jmespath>=0.9.5 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from itemloaders>=1.0.1->scrapy>=2.5.0->advertools) (0.10.0)\n",
      "Requirement already satisfied: six>=1.6.0 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from parsel>=1.5.0->scrapy>=2.5.0->advertools) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from requests>=2.1.0->twython>=3.8.0->advertools) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from requests>=2.1.0->twython>=3.8.0->advertools) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from requests>=2.1.0->twython>=3.8.0->advertools) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from requests>=2.1.0->twython>=3.8.0->advertools) (2023.7.22)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from requests-oauthlib>=0.4.0->twython>=3.8.0->advertools) (3.2.2)\n",
      "Requirement already satisfied: attrs>=16.0.0 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from service-identity>=18.1.0->scrapy>=2.5.0->advertools) (22.1.0)\n",
      "Requirement already satisfied: pyasn1-modules in c:\\users\\vhafu\\.conda\\lib\\site-packages (from service-identity>=18.1.0->scrapy>=2.5.0->advertools) (0.2.8)\n",
      "Requirement already satisfied: constantly>=15.1 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from Twisted>=18.9.0->scrapy>=2.5.0->advertools) (15.1.0)\n",
      "Requirement already satisfied: incremental>=21.3.0 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from Twisted>=18.9.0->scrapy>=2.5.0->advertools) (21.3.0)\n",
      "Requirement already satisfied: Automat>=0.8.0 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from Twisted>=18.9.0->scrapy>=2.5.0->advertools) (20.2.0)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from Twisted>=18.9.0->scrapy>=2.5.0->advertools) (21.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from Twisted>=18.9.0->scrapy>=2.5.0->advertools) (4.7.1)\n",
      "Requirement already satisfied: twisted-iocpsupport<2,>=1.0.2 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from Twisted>=18.9.0->scrapy>=2.5.0->advertools) (1.0.2)\n",
      "Requirement already satisfied: requests-file>=1.4 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from tldextract->scrapy>=2.5.0->advertools) (1.5.1)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\users\\vhafu\\.conda\\lib\\site-packages (from tldextract->scrapy>=2.5.0->advertools) (3.9.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\vhafu\\.conda\\lib\\site-packages (from cffi>=1.12->cryptography>=3.4.6->scrapy>=2.5.0->advertools) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install advertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4badec05",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVC\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mlgb\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LGBMClassifier\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "# Data analysis and wrangling libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Visualisations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Preprocessing\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "# Modelling\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import advertools as adv\n",
    "\n",
    "# Metrics for Model Evaluation\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import  log_loss\n",
    "import time\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "# Libraries to Save/Restore Models\n",
    "import pickle\n",
    "# Downloads\n",
    "nltk.download(['punkt','stopwords'])\n",
    "%matplotlib inline\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4630a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002B2D2836E10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/catboost/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002B2D280A390>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/catboost/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002B2D280E110>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/catboost/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002B2D281F350>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/catboost/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002B2D281FED0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/catboost/\n",
      "ERROR: Could not find a version that satisfies the requirement catboost (from versions: none)\n",
      "ERROR: No matching distribution found for catboost\n"
     ]
    }
   ],
   "source": [
    "%pip install catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19620521",
   "metadata": {},
   "source": [
    "# 2. Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4210da83",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load train data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load test data\u001b[39;00m\n\u001b[0;32m      5\u001b[0m test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\.conda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\.conda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\.conda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\.conda\\Lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input'"
     ]
    }
   ],
   "source": [
    "# Load train data\n",
    "train = pd.read_csv('/kaggle/input')\n",
    "\n",
    "# Load test data\n",
    "test = pd.read_csv('/kaggle/input')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2748ff20",
   "metadata": {},
   "source": [
    "# 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9575ddd",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 2) (873508.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[13], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    'train'.head'(10)\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 2)\n"
     ]
    }
   ],
   "source": [
    "# to view the first 10 rows of the train data\n",
    "'train'.head'(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34d82ed1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# view the info for both data set.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minformation of TRAIN dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain\u001b[38;5;241m.\u001b[39minfo()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minformationof TEST dataaet: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest\u001b[38;5;241m.\u001b[39minfo()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "# view the info for both data set.\n",
    "print(f'information of TRAIN dataset: {train.info()}')\n",
    "print(f'informationof TEST dataaet: {test.info()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d19a994",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Distributin of each language \u001b[39;00m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m sns\u001b[38;5;241m.\u001b[39mcountplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlang_id\u001b[39m\u001b[38;5;124m'\u001b[39m,data\u001b[38;5;241m=\u001b[39mtrain, palette\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautumn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount of lang_id\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distributin of each language \n",
    "plt.figure(figsize=(12,6))\n",
    "sns.countplot(x='lang_id',data=train, palette=\"autumn\")\n",
    "plt.title('Count of lang_id\\n')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3e371ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# view the info for both data set.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minformation of TRAIN dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain\u001b[38;5;241m.\u001b[39minfo()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minformationof TEST dataaet: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest\u001b[38;5;241m.\u001b[39minfo()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "# view the info for both data set.\n",
    "print(f'information of TRAIN dataset: {train.info()}')\n",
    "print(f'informationof TEST dataaet: {test.info()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19968cde",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb3afcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
